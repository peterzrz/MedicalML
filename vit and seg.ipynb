{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"y3eZzmsRX_P1"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import os\n","\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pwGDAhpcMA7o","executionInfo":{"status":"ok","timestamp":1681871286724,"user_tz":-480,"elapsed":21934,"user":{"displayName":"CQ Xia","userId":"07412010291635966604"}},"outputId":"4ae17714-72e1-4dc3-eb6f-e7e43dde3375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["VIT"],"metadata":{"id":"MBjAj4kno0t-"}},{"cell_type":"code","source":["def load_npy_files(image_npy_path, mask_npy_path):\n","    images = np.load(image_npy_path)\n","    masks = np.load(mask_npy_path)\n","    return images, masks\n","\n","def data_augmentation(images, masks, batch_size=8):\n","    data_gen_args = dict(rotation_range=20,\n","                         width_shift_range=0.1,\n","                         height_shift_range=0.1,\n","                         shear_range=0.1,\n","                         zoom_range=0.2,\n","                         horizontal_flip=True,\n","                         fill_mode='nearest')\n","    \n","    image_datagen = ImageDataGenerator(**data_gen_args)\n","    mask_datagen = ImageDataGenerator(**data_gen_args)\n","\n","    image_datagen.fit(images, augment=True, seed=1)\n","    mask_datagen.fit(masks, augment=True, seed=1)\n","\n","    image_generator = image_datagen.flow(images, batch_size=batch_size, seed=1)\n","    mask_generator = mask_datagen.flow(masks, batch_size=batch_size, seed=1)\n","\n","    return zip(image_generator, mask_generator)\n","\n","def visualize_augmented_data(images, masks, num_images_to_show=3):\n","    for i in range(num_images_to_show):\n","        image, mask = images[i], masks[i]\n","        image_augmented, mask_augmented = next(data_augmentation(np.array([image]), np.array([mask])))\n","\n","        cv2_imshow(image)\n","        cv2_imshow(mask)\n","        cv2_imshow(image_augmented[0])\n","        cv2_imshow(mask_augmented[0])\n","\n","        cv2.waitKey(0)\n","        cv2.destroyAllWindows()\n","\n","if __name__ == \"__main__\":\n","    image_npy_path = '/content/drive/MyDrive/EECS545 Final Project/train_input0.npy' # Since i don't have Mingyu's label files so I used face.npy in hw5 to check my code\n","    mask_npy_path = '/content/drive/MyDrive/EECS545 Final Project/train_label0.npy'\n","\n","    images, masks = load_npy_files(image_npy_path, mask_npy_path)\n","\n","    images = np.expand_dims(images, axis=-1)  \n","    masks = np.expand_dims(masks, axis=-1)\n","\n","    visualize_augmented_data(images, masks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"kjhd6_r1YCKu","executionInfo":{"status":"error","timestamp":1681872035998,"user_tz":-480,"elapsed":48375,"user":{"displayName":"CQ Xia","userId":"07412010291635966604"}},"outputId":"1e1635dc-c698-44bc-9309-edfcde025dc4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a2e5685255ca>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mvisualize_augmented_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-a2e5685255ca>\u001b[0m in \u001b[0;36mvisualize_augmented_data\u001b[0;34m(images, masks, num_images_to_show)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images_to_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mimage_augmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-a2e5685255ca>\u001b[0m in \u001b[0;36mdata_augmentation\u001b[0;34m(images, masks, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmask_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_gen_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimage_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmask_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[1;32m   2085\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2087\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2088\u001b[0m                 \u001b[0;34m\"Input to `.fit()` should have rank 4. Got array with shape: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input to `.fit()` should have rank 4. Got array with shape: (1, 3, 310, 360, 1)"]}]},{"cell_type":"markdown","source":["segmentation"],"metadata":{"id":"xJxSb-uto4RI"}},{"cell_type":"code","source":["import numpy as np\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"],"metadata":{"id":"SQeIrxOeolkg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def unet_model(input_size=(256, 256, 1)):\n","    inputs = Input(input_size)\n","    \n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = BatchNormalization()(c1)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    c1 = BatchNormalization()(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","\n","    # ... [add more layers following the U-Net architecture] ...\n","\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u8) # this part is incorrect, it seems that u8 in colab doesn't work\n","    c9 = BatchNormalization()(c9)\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9) # this part is incorrect, same error as above\n","    c9 = BatchNormalization()(c9)\n","\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9) # this part is incorrect, same error as above\n","\n","    model = Model(inputs=[inputs], outputs=[outputs])\n","\n","    return model\n","\n","def train_unet(images, masks, epochs=50, batch_size=8):\n","    model = unet_model(input_size=(images.shape[1], images.shape[2], images.shape[3]))\n","\n","    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    model_checkpoint = ModelCheckpoint('unet_weights.hdf5', monitor='val_loss', save_best_only=True)\n","    early_stopping = EarlyStopping(patience=10, verbose=1)\n","\n","    model.fit(images, masks, batch_size=batch_size, epochs=epochs, verbose=1,\n","              validation_split=0.2, shuffle=True, callbacks=[model_checkpoint, early_stopping])\n","\n","    return model\n","\n","if __name__ == \"__main__\":\n","    image_npy_path = 'face.npy' \n","    mask_npy_path = 'face.npy'\n","\n","    images, masks = load_npy_files(image_npy_path, mask_npy_path)\n","\n","    # Normalize images and masks to [0, 1] range\n","    images = images.astype(np.float32) / 255.0\n","    masks = masks.astype(np.float32) / 255.0\n","\n","    # Train U-Net model\n","    model = train_unet(images, masks)"],"metadata":{"id":"7F_2Nc3Zol8R"},"execution_count":null,"outputs":[]}]}